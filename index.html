<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SMISTS: Simulated Misinformation Susceptibility Tests">
  <meta name="keywords" content="SMISTS">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SMISTS: Simulated Misinformation Susceptibility Tests</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/salt-logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* Three image containers (use 25% for four, and 50% for two, etc) */
    .imgcolumn {
      float: left;
      width: 50%;
      padding: 10px
    }

    /* Clear floats after image containers */
    .imgrow::after {
      content: "";
      clear: both;
      display: table;
    }

    table.customTable {
      width: 50%;
      background-color: #FFFFFF;
      border-collapse: collapse;
      border-width: 2px;
      border-color: rgb(214, 236, 244);
      border-style: solid;
      color: #000000;
      margin-left: auto;
      margin-right: auto;
    }
    
    table.customTable td {
      border-width: 2px;
      border-color: rgb(214, 236, 244);
      border-style: solid;
      padding: 5px;
      text-align: center; 
      vertical-align: middle;
    }

    table.customTable th {
      border-width: 2px;
      border-color: rgb(214, 236, 244);
      border-style: solid;
      padding: 5px;
    }
    
    table.customTable thead {
      background-color: rgb(214, 236, 244);
    }
    </style>
</head>
<body>
  
  

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SMISTS: Simulated Misinformation Susceptibility Tests</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="hikari-NYU.github.io">Weicheng Ma</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://charlesdddd.github.io/">Chunyuan Deng</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://aclanthology.org/people/a/aram-moossavi/">Aram Moosavi</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://web.cs.dartmouth.edu/people/lili-wang">Lili Wang</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://web.cs.dartmouth.edu/people/soroush-vosoughi">Soroush Vosoughi</a><sup>5</sup>,</span>
            <span class="author-block">
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a><sup>6</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1, 3, 4, 5</sup>Dartmouth College,</span>
            <span class="author-block"><sup>2</sup>Georgia Tech,</span>
            <span class="author-block"><sup>6</sup>Stanford University,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <img src="./static/images/Dartmouth-College-Logo.png" width="200" align="absmiddle" />
            </span>
            <span class="author-block">
              <img src="./static/images/GeorgiaTech_RGB.png" width="200" align="absmiddle"/>  
            </span>
            <span class="author-block">
              <img src="./static/images/stanford-university-logo-2.png" style="margin-right: 50px;" width="200" align="absmiddle"/>  
            </span><!---->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://aclanthology.org/2024.findings-acl.162.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/hikari-NYU/SMIST"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Psychological inoculation, a strategy to build resistance against persuasive misinformation, has been shown to reduce its spread and adverse effects. Although these inoculations are effective, the design and optimization of them typically require substantial financial and human resources. To address these challenges, this work introduces Simulated Misinformation Susceptibility Test (SMIST), leveraging Large Language Models (LLMs) to simulate participant responses in misinformation studies.
SMIST employs a life experience-driven simulation methodology, which accounts for various aspects of participants' backgrounds, to mitigate common issues of caricatures and stereotypes in LLM simulations and enhance response diversity. Our extensive experimentation demonstrates that SMIST, utilizing GPT-4 as the backend model, yields results that align closely with those obtained from human-subject studies in misinformation susceptibility. This alignment suggests that LLMs can effectively serve as proxies in evaluating the impact of psychological inoculations.
Further, SMIST can be applied to emerging and anticipated misinformation scenarios without harming human participants, thereby expanding the scope of misinformation research.

          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Overall Framework</h2>
          <p>Comparative illustration of the processes in human-subject MIST (top) and SMIST (bottom). Red and green boxes demonstrate cons of MIST and pros of SMIST, respectively. Q indicates the questionnaire. In SMIST, while all simulated participants within a group share specified demographic characteristics, they exhibit diversity in other uncontrolled aspects.</p>
          <img src="./static/images/misinfo_fig1.png" class="example-image" alt="Example image."/>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Data Preparation</h2>
          <p>The study gathered verified misinformation on COVID-19, the Russo-Ukraine war, the 2020 US election, GMOs, and climate change from reputable sources like The New York Times, Wikipedia, and the Alliance for Science, each with a correction to create an authentic information corpus. COVID-19 misinformation was also rephrased into satire and conspiracy theory styles by a domain expert to explore susceptibility to these formats. Additionally, recent misinformation fact-checked by Snopes was included to assess the systemâ€™s ability to handle unfamiliar misinformation, ensuring robustness and validation for both human and model-based evaluations.</p>
          <center><img src="./static/images/misinfo_fig2.png" class="example-image" alt="Example image." style="width: 80%;"/></center>
          <!-- <center><img src="./static/images/gsm8k_table.png" class="example-image" alt="Example image." style="width: 60%;" /></center>
          <center><img src="./static/images/radar.png" class="example-image" alt="Example image." style="width: 80%;" /></center> -->
          <p>The construction process of (a) an \ul{original fact-checked misinformation \& genuine information dataset}, (b) a \ul{COVID-19-related satire \& conspiracy theory dataset}, and (c) a \ul{recent misinformation dataset} containing misinformation fact-checked on Snopes after 02/04/2024. The number of (mis)information pieces under each category is also displayed.</p>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Social Reasoning</h2>
          <p>We evaluate SOTA LLMs on the Bias Benchmark for QA (BBQ) using DARG with reasoning graphs that have an increased number of attribute nodes and modified attributes' polarity. The metrics are accuracy, bias score, and Overall Avoidance Rate, which measures how often LLMs are overly sensitive to contexts involving protected groups, often choosing 'Cannot be determined.' even when clear evidence supports an answer. LLMs perform worse as complexity increases and show increasing biases towards protected groups.</p>
          <center><img src="./static/images/bbq_cot_results.png" class="example-image" alt="Example image." style="width: 80%;" /></center>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Methodology</h2>
          <p>We evaluate SOTA LLMs on the BIG-Bench Hard (BBH) Navigate dataset, a spatial reasoning dataset that involves giving the LLM
            navigation steps to determine if the agent returns to the starting point. As the depth of the reasoning graph
            increases, most LLMs' overall accuracy drops, with a significant decline in accuracy on positive cases (where the label is 'Yes')
            while the accuracy on negative cases remains comparatively stable, indicating biases.</p>
          <div class="columns">
            <div class="column is-one-third">
              <img src="./static/images/navigate_overall.png" class="example-image" alt="Overall performance image." />
            </div>
            <div class="column is-one-third">
              <img src="./static/images/navigate_negative.png" class="example-image"
                alt="Negative case performance image." />
            </div>
            <div class="column is-one-third">
              <img src="./static/images/navigate_positive.png" class="example-image"
                alt="Positive case performance image." />
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Symbolic Reasoning</h2>
          <p>We evaluate SOTA LLMs on the BIG-Bench Hard (BBH) Dyck Language dataset, a symbolic reasoning dataset that requires the model to predict the sequence of closing parentheses for a Dyck-4 word missing its last few closing parentheses. As the depth of the reasoning graph's input and output parts increases, all LLMs' performances tend to decrease.</p>
          <img src="./static/images/BBH_dyck_results.png" class="example-image" alt="Example image."/>
        </div>
      </div>
    </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Finetune LLMs with DARG generated data</h2>
          <p>We compare Llama2-7B and Mistral-7B finetuned with DARG generated data and the origical GSM8K's training data, both models finetuned with DARG generated data can outperform the one finetuned with an equivalent amount of GSM8K's
          original training data. This demonstrates DARG's potential not only to dynamically generate new test samples but also
          to produce training data that enables LLMs to adapt to various complexity levels.</p>
          <center><img src="./static/images/finetuned_results.png" class="example-image" alt="Example image." style="width: 60%;" /></center>
        </div>
      </div>
    </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{ma2024simulated,
      title={Simulated misinformation susceptibility (smists): Enhancing misinformation research with large language model simulations},
      author={Ma, Weicheng and Deng, Chunyuan and Moossavi, Aram and Wang, Lili and Vosoughi, Soroush and Yang, Diyi},
      booktitle={Findings of the Association for Computational Linguistics ACL 2024},
      pages={2774--2788},
      year={2024}
    }</code></pre>
  </div>
</section>


<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Usage and License Notices</h2>
    <p>
      The data, code and model checkpoint are intended and licensed for research use only. Please do not use them for any malicious purposes.
    </p>
    <p>
      The benchmark is built on top of the C4 dataset, under the ODC Attribution License (ODC-By). 
    </p>
    <p>
      This website is licensed under a <a rel="license"
                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
    <p>
      This source code of this website is borrowed from <a
        href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
    </p>
  </div>
</section>


<!-- 
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This source code of this website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>
</html>
